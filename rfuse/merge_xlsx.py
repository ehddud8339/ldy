import os
import re
import argparse
from collections import defaultdict, OrderedDict
import pandas as pd

def parse_summary_sheet(xlsx_path, sheet_name="Sheet1"):
    """
    Parse a [workload]_summary.xlsx generated by the prior script.
    Returns:
      blocks: dict keyed by (workload, bs) with value:
        {
          "numjobs": [list of ints],
          "metrics": {
             "IOPS": [values],
             "BW(mb/s)": [...],
             "lat_avg(us)": [...],
             "p95_lat(us)": [...],
             "p99_lat(us)": [...],
          }
        }
    """
    # Read raw values with header=None to preserve exact layout
    df = pd.read_excel(xlsx_path, sheet_name=sheet_name, header=None)
    nrows, ncols = df.shape
    blocks = OrderedDict()

    r = 0
    while r < nrows:
        # Find a title row: A(empty), B has like 'workload_bs'
        title = df.iat[r, 1] if 1 < ncols else None
        a0 = df.iat[r, 0] if 0 < ncols else None
        if isinstance(title, str) and (a0 is None or (isinstance(a0, float) and pd.isna(a0)) or a0 == ""):
            # likely a header row
            # Next row should be numjobs header
            if r + 1 >= nrows: break
            # Collect numjobs from columns 1.. until NaN
            nj_row = df.iloc[r+1, 1:]
            numjobs = []
            for val in nj_row:
                if pd.isna(val): break
                try:
                    numjobs.append(int(val))
                except Exception:
                    break
            if not numjobs:
                r += 1
                continue

            # Consume next metric rows (up to expected list)
            metrics_order = ["IOPS", "BW(mb/s)", "lat_avg(us)", "p95_lat(us)", "p99_lat(us)"]
            metric_rows = {}
            rr = r + 2
            for mname in metrics_order:
                if rr >= nrows: break
                label = df.iat[rr, 0] if 0 < ncols else None
                if label != mname:
                    # not matching expected; stop block
                    break
                vals = []
                row_vals = df.iloc[rr, 1:1+len(numjobs)]
                for v in row_vals:
                    if pd.isna(v):
                        vals.append(None)
                    else:
                        try:
                            vals.append(float(v))
                        except Exception:
                            vals.append(None)
                metric_rows[mname] = vals
                rr += 1

            # Ensure we got at least IOPS row to confirm block
            if "IOPS" in metric_rows:
                # title is like 'workload_bs'
                if "_" in title:
                    parts = title.split("_", 1)
                    workload, bs = parts[0], parts[1]
                else:
                    workload, bs = title, ""
                blocks[(workload, bs)] = {
                    "numjobs": numjobs,
                    "metrics": metric_rows
                }
                # Advance beyond block plus spacer (we left some rows after metrics)
                r = rr + 2
                continue
        r += 1

    return blocks

def merge_files(dir_path, out_path, sheet_name="Sheet1"):
    """
    Scan dir_path for '*_summary.xlsx', parse each as a filesystem entry (fsname),
    and produce a combined summary.xlsx in the format of format_summary.xlsx.
    """
    files = [f for f in os.listdir(dir_path) if f.lower().endswith("_summary.xlsx")]
    if not files:
        raise SystemExit(f"No *_summary.xlsx files found in {dir_path}")

    # Determine fsname from filename stem
    def fs_name_from(fname):
        base = os.path.splitext(fname)[0]
        if base.endswith("_summary"):
            base = base[:-len("_summary")]
        return base

    # Parse all files
    per_fs = {}  # fs -> blocks dict
    for fname in files:
        fpath = os.path.join(dir_path, fname)
        try:
            blocks = parse_summary_sheet(fpath, sheet_name=sheet_name)
            per_fs[fs_name_from(fname)] = blocks
        except Exception as e:
            raise RuntimeError(f"Failed to parse {fpath}: {e}")

    # Union of (workload, bs)
    all_keys = set()
    for blocks in per_fs.values():
        all_keys |= set(blocks.keys())
    # Stable order by workload, bs
    all_keys = sorted(all_keys, key=lambda x: (x[0], x[1]))

    # Desired row order for filesystems, then any others
    fs_priority = ["ext4", "fuse", "rfuse"]
    other_fs = sorted([fs for fs in per_fs.keys() if fs not in fs_priority])
    fs_row_order = [fs for fs in fs_priority if fs in per_fs] + other_fs

    metrics_order = ["IOPS", "BW(mb/s)", "lat_avg(us)", "p95_lat(us)", "p99_lat(us)"]

    with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
        wb = writer.book
        ws = wb.add_worksheet("Sheet2")
        writer.sheets["Sheet2"] = ws

        fmt_header = wb.add_format({"align":"center","valign":"vcenter","bold":True,"border":1})
        fmt_metric = wb.add_format({"align":"left","valign":"vcenter","border":1})
        fmt_fs = wb.add_format({"align":"left","valign":"vcenter","border":1})
        fmt_cell = wb.add_format({"align":"right","valign":"vcenter","num_format":"0.00","border":1})
        fmt_int = wb.add_format({"align":"right","valign":"vcenter","num_format":"0","border":1})

        row = 0
        for (workload, bs) in all_keys:
            # Establish union numjobs across FS for this (workload, bs)
            nj_union = set()
            for fs, blocks in per_fs.items():
                if (workload, bs) in blocks:
                    nj_union |= set(blocks[(workload, bs)]["numjobs"])
            numjobs = sorted(nj_union)
            if not numjobs:
                continue

            # For each metric create a block (like format_summary.xlsx)
            for metric in metrics_order:
                title = f"{workload}_{bs}_{metric}"
                # Header merged across B..
                ws.merge_range(row, 1, row, 1+len(numjobs)-1, title, fmt_header)
                row += 1

                # numjobs header
                ws.write(row, 0, "", fmt_header)
                for j, nj in enumerate(numjobs, start=1):
                    ws.write(row, j, nj, fmt_header)
                row += 1

                # Rows: each filesystem
                for fs in fs_row_order:
                    ws.write(row, 0, fs, fmt_fs)
                    # Fetch values aligned by numjobs
                    if (fs in per_fs) and ((workload, bs) in per_fs[fs]):
                        blk = per_fs[fs][(workload, bs)]
                        base_nj = blk["numjobs"]
                        mvals = blk["metrics"].get(metric, None)
                        # Map njob->value
                        d = {}
                        if mvals is not None:
                            for nj, v in zip(base_nj, mvals):
                                d[int(nj)] = v
                        # Write in union order
                        for j, nj in enumerate(numjobs, start=1):
                            val = d.get(int(nj), None)
                            if val is None:
                                ws.write(row, j, "", fmt_cell)
                            else:
                                if metric == "IOPS":
                                    # Integer display
                                    try:
                                        ws.write(row, j, round(float(val)), fmt_int)
                                    except Exception:
                                        ws.write(row, j, "", fmt_cell)
                                else:
                                    try:
                                        ws.write(row, j, float(val), fmt_cell)
                                    except Exception:
                                        ws.write(row, j, "", fmt_cell)
                    else:
                        # no data for this fs
                        for j in range(1, 1+len(numjobs)):
                            ws.write(row, j, "", fmt_cell)
                    row += 1

                # spacer
                row += 1

            # extra spacer between (workload, bs) groups
            row += 1

        ws.set_column(0, 0, 14)
        ws.set_column(1, 200, 12)

def main():
    ap = argparse.ArgumentParser(description="Merge [workload]_summary.xlsx files into summary.xlsx with format like format_summary.xlsx")
    ap.add_argument("dir", help="Directory containing *_summary.xlsx files")
    ap.add_argument("--out", default=None, help="Output Excel path (default: summary.xlsx in given dir)")
    args = ap.parse_args()

    dir_path = os.path.abspath(args.dir)
    if not os.path.isdir(dir_path):
        raise SystemExit(f"Not a directory: {dir_path}")
    out_path = args.out or os.path.join(dir_path, "summary.xlsx")
    merge_files(dir_path, out_path)
    print(f"Wrote merged summary: {out_path}")

if __name__ == "__main__":
    main()

